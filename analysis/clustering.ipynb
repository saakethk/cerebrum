{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "025c6861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tslearn\n",
      "  Downloading tslearn-0.7.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: scikit-learn>=1.4 in /Users/saake/Documents/Personal Development/cerebrum/venv/lib/python3.13/site-packages (from tslearn) (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.24.3 in /Users/saake/Documents/Personal Development/cerebrum/venv/lib/python3.13/site-packages (from tslearn) (2.4.2)\n",
      "Requirement already satisfied: scipy>=1.10.1 in /Users/saake/Documents/Personal Development/cerebrum/venv/lib/python3.13/site-packages (from tslearn) (1.17.0)\n",
      "Collecting numba>=0.58.1 (from tslearn)\n",
      "  Downloading numba-0.63.1-cp313-cp313-macosx_12_0_arm64.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: joblib>=1.2 in /Users/saake/Documents/Personal Development/cerebrum/venv/lib/python3.13/site-packages (from tslearn) (1.5.3)\n",
      "Collecting llvmlite<0.47,>=0.46.0dev0 (from numba>=0.58.1->tslearn)\n",
      "  Downloading llvmlite-0.46.0-cp313-cp313-macosx_12_0_arm64.whl.metadata (5.0 kB)\n",
      "Collecting numpy>=1.24.3 (from tslearn)\n",
      "  Using cached numpy-2.3.5-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /Users/saake/Documents/Personal Development/cerebrum/venv/lib/python3.13/site-packages (from scikit-learn>=1.4->tslearn) (3.6.0)\n",
      "Downloading tslearn-0.7.0-py3-none-any.whl (372 kB)\n",
      "Downloading numba-0.63.1-cp313-cp313-macosx_12_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.46.0-cp313-cp313-macosx_12_0_arm64.whl (37.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.2/37.2 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached numpy-2.3.5-cp313-cp313-macosx_14_0_arm64.whl (5.1 MB)\n",
      "Installing collected packages: numpy, llvmlite, numba, tslearn\n",
      "\u001b[2K  Attempting uninstall: numpy\n",
      "\u001b[2K    Found existing installation: numpy 2.4.2\n",
      "\u001b[2K    Uninstalling numpy-2.4.2:\n",
      "\u001b[2K      Successfully uninstalled numpy-2.4.2\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [tslearn]m3/4\u001b[0m [tslearn]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed llvmlite-0.46.0 numba-0.63.1 numpy-2.3.5 tslearn-0.7.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tslearn\n",
    "import tslearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d815474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84127f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            date symbol  day_returns\n",
      "0     2025-01-02   NVDA     0.029935\n",
      "1     2025-01-03   NVDA     0.044538\n",
      "2     2025-01-06   NVDA     0.034332\n",
      "3     2025-01-07   NVDA    -0.062170\n",
      "4     2025-01-08   NVDA    -0.000214\n",
      "...          ...    ...          ...\n",
      "1495  2025-12-24   META     0.003925\n",
      "1496  2025-12-26   META    -0.006382\n",
      "1497  2025-12-29   META    -0.006935\n",
      "1498  2025-12-30   META     0.011022\n",
      "1499  2025-12-31   META    -0.008799\n",
      "\n",
      "[1500 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from data import Data\n",
    "\n",
    "# Get all data in pandas dataframe\n",
    "interest_stocks = [\"NVDA\", \"GOOGL\", \"AAPL\", \"MSFT\", \"AMZN\", \"META\"]\n",
    "all_data = Data.get_symbols_returns(symbols=interest_stocks, length=250)\n",
    "print(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fb35cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date    2025-01-02  2025-01-03  2025-01-06  ...  2025-12-29  2025-12-30  2025-12-31\n",
      "symbol                                      ...                                    \n",
      "AAPL     -0.026236   -0.002009    0.006739  ...    0.001317   -0.002484   -0.004468\n",
      "AMZN      0.003783    0.018027    0.015255  ...   -0.001935    0.001982   -0.007354\n",
      "GOOGL     0.000687    0.012458    0.026487  ...    0.000159    0.000925   -0.002708\n",
      "META      0.023450    0.008995    0.042290  ...   -0.006935    0.011022   -0.008799\n",
      "MSFT     -0.006928    0.011396    0.010630  ...   -0.001251    0.000780   -0.007918\n",
      "NVDA      0.029935    0.044538    0.034332  ...   -0.012124   -0.003613   -0.005545\n",
      "\n",
      "[6 rows x 250 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "all_data = all_data.sort_values([\"symbol\", \"date\"])\n",
    "pivot = all_data.pivot(index=\"symbol\", columns=\"date\", values=\"day_returns\")\n",
    "print(pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f967e5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 250, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "model_inputs = pivot.values[:, :, np.newaxis]\n",
    "print(model_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5b6ba9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling time series using tslearn TimeSeriesScalerMeanVariance\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "\n",
    "scaler = TimeSeriesScalerMeanVariance()\n",
    "model_inputs_scaled = scaler.fit_transform(model_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1e8476b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saake/Documents/Personal Development/cerebrum/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:95: FutureWarning: Function stable_cumsum is deprecated; `sklearn.utils.extmath.stable_cumsum` is deprecated in version 1.8 and will be removed in 1.10. Use `np.cumulative_sum` with the desired dtype directly instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "\n",
    "model = TimeSeriesKMeans(\n",
    "    n_clusters=3,\n",
    "    metric=\"dtw\",\n",
    "    max_iter=25,\n",
    "    metric_params={\"sakoe_chiba_radius\": 5},  # speed constraint\n",
    "    random_state=0,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "labels = model.fit_predict(model_inputs_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae0129ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        stock  cluster\n",
      "symbol                \n",
      "AAPL     AAPL        2\n",
      "AMZN     AMZN        2\n",
      "GOOGL   GOOGL        1\n",
      "META     META        2\n",
      "MSFT     MSFT        0\n",
      "NVDA     NVDA        0\n"
     ]
    }
   ],
   "source": [
    "cluster_map = pivot.index.to_series().to_frame(name=\"stock\")\n",
    "cluster_map[\"cluster\"] = labels\n",
    "print(cluster_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f864b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
